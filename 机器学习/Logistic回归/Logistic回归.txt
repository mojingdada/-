1.根据现有数据对分类边界线建立回归公式，以此进行分类。
2.Sigmoid函数
当x为0时，函数值为0.5；随着x值的增大，对应的Sigmoid值接近1；而随着x的减小，Sigmoid值将逼近0.
3.基于最优化方法的最佳回归系数的确定。
4.梯度上升算法用来求函数的最大值，而梯度下降算法用来求函数的最小值。
5.随机梯度上升
梯度上升每次需要遍历整个数据集，如果数据特征值过多，那么该方法计算的复杂度就太高了。
一种改进的方法是一次仅用一个样本点来更新回归系数，该方法称为随机梯度上升算法。
6.改进的随机梯度上升算法
（1）alpha每次迭代需要调整。
（2）随机选取样本。
7.处理数据中的缺失值
（1）使用可用特征的均值来填补缺失值。
（2）使用特殊值来填补缺失值，如-1。
（3）忽略有缺失值的样本。
（4）使用相似样本的均值来填补缺失值。
（5）使用另外的机器学习算法预测缺失值。
8.算法过程
（1）输入训练样本。
（2）利用改进的随机梯度上升算法求出weights值。
（3）输入测试样本。
（4）利用sigmoid函数和刚刚得到的weights值求出预测分类。
（5）将得到的预测分类与测试样本分类做比较得出正确率。
